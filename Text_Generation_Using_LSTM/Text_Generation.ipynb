{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBnS0e3zbCE9"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssUMBXMqeHqt"
      },
      "source": [
        "filename = \"/content/NewFile.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGX4r6sweHtm"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sylzE6BveHwS",
        "outputId": "b79fa535-b515-416e-8be1-1648e3c54cd7"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163780\n",
            "Total Vocab:  58\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVvgfviFeH_W",
        "outputId": "c2e6c4df-3ce0-4b61-81e7-99bbec331e9e"
      },
      "source": [
        "#creating an input and output pair encoded as an integer\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5bIBxWceICN",
        "outputId": "6629989e-8389-4514-fb64-dcd87d9a37ce"
      },
      "source": [
        "X=np.reshape(dataX,(n_patterns,seq_length,1))\n",
        "X = X / float(n_vocab)\n",
        "y = np_utils.to_categorical(dataY)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(163680, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWJFreTZeIFE"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i1JIftmihdG",
        "outputId": "9ea6db79-875b-47c7-95a1-1c6e3d0e6074"
      },
      "source": [
        "#filepath=\"weights-improvement.hdf5\"\n",
        "#checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "#callbacks_list = [checkpoint]\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=20, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.8790 - accuracy: 0.4547\n",
            "Epoch 2/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.8383 - accuracy: 0.4658\n",
            "Epoch 3/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.8060 - accuracy: 0.4746\n",
            "Epoch 4/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.7768 - accuracy: 0.4825\n",
            "Epoch 5/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.7409 - accuracy: 0.4907\n",
            "Epoch 6/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.7171 - accuracy: 0.4964\n",
            "Epoch 7/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.6910 - accuracy: 0.5041\n",
            "Epoch 8/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.6683 - accuracy: 0.5095\n",
            "Epoch 9/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.6455 - accuracy: 0.5148\n",
            "Epoch 10/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.6247 - accuracy: 0.5204\n",
            "Epoch 11/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.6073 - accuracy: 0.5251\n",
            "Epoch 12/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.5842 - accuracy: 0.5301\n",
            "Epoch 13/20\n",
            "1279/1279 [==============================] - 40s 32ms/step - loss: 1.5692 - accuracy: 0.5341\n",
            "Epoch 14/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.5508 - accuracy: 0.5392\n",
            "Epoch 15/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.5367 - accuracy: 0.5435\n",
            "Epoch 16/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.5215 - accuracy: 0.5470\n",
            "Epoch 17/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.5036 - accuracy: 0.5516\n",
            "Epoch 18/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.4936 - accuracy: 0.5541\n",
            "Epoch 19/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.4813 - accuracy: 0.5562\n",
            "Epoch 20/20\n",
            "1279/1279 [==============================] - 41s 32ms/step - loss: 1.4675 - accuracy: 0.5615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f059424fc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4G3eUA2ihaW"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf2JdOMzihXb",
        "outputId": "f9764567-6ac4-43a7-e123-ba17db9866b3"
      },
      "source": [
        "import sys\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)] \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start\n",
            "\" g more: at last came a\n",
            "rumbling of little cartwheels, and the sound of a good many voices\n",
            "all talkin \"\n",
            "g and satier and foon. \n",
            "'ooe of the sort of the shate os she shing it to see that it was an anl of line and a good of the sable. \n",
            "'what sat the rame to tell you a good tay ' she said to herself, 'and the rearon in the sea. \n",
            "'the pueen was a good deal of the thing which when the cook her fands, and she was so see what the was selling on the sable. 'i must be she sea- the mock turtle to get in the lors- i should think i mnow that it say it makes the sea- the mock turtle say it a linute or two the pooy of the thing of the shate of the shate of the sable. \n",
            "'well, i don't know the sabeit would be a seree of the sort!' she mock turtle replied. 'thete's no moog of the shane oo the bance.\n",
            "\n",
            "'then the rabeit would be a preat puz of the sort, and the sea,''then she sas oo the sable with the garter, and the shme she was serling of the sort of the thing of the sort of the thing of the shate of the thing of the thing of the project gutenberg-tm electronic works in the project gutenberg-tm license to\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYrAKM-YihUx"
      },
      "source": [
        "model.save(\"Text.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr8K6ywBihR7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}